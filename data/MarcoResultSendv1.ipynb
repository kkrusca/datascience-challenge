{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "I first import the training and testing data. I aggregate all testing dataset for each company into a unique testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries I need\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the training data \n",
    "training = pd.read_pickle('labelled_dataset.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the testing data\n",
    "cwd = os.getcwd()\n",
    "# define the data directory\n",
    "data_dir = cwd +\"/unlabelled-dataset/\"\n",
    "file_list = os.listdir(data_dir)\n",
    "\n",
    "# loop inside the list of companies' files and aggregate them\n",
    "dummy = pd.DataFrame(columns=['text','company'])\n",
    "testing = []#pd.DataFrame(columns=['text'])\n",
    "for k in file_list:\n",
    "    with open(data_dir + k, 'r') as f:\n",
    "        array = json.load(f)\n",
    "    \n",
    "    #print (array)\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        dummy= [array[i]['text'],k[:-5]]\n",
    "        testing.append(dummy)\n",
    "\n",
    " # define the testing dataset                     \n",
    "testing = pd.DataFrame(testing,  columns= ['text', 'company'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now convert the words into ad dictionary: I vectorialise the sentences using CountVectorizer which takes the words of each sentence and creates a vocabulary of all the unique words in the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "sentences_train = training[\"text\"].values\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(testing[\"text\"].values)\n",
    "#X_train\n",
    "y = training['labelmax'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "I first try a naïve Bayes classification and then the most natural logistic regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes\n",
    "I fit the model and look at the accuracy of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy during training (NB) 0.6349967241755842\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "\n",
    "Naive.fit(X_train,y)\n",
    "scoreNB_over = Naive.score(X_train, y)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "print(\"Accuracy during training (NB)\", scoreNB_over)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naïve Bayes does not reach the 90% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic  regression\n",
    "I try now with the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(multi_class = 'auto', n_jobs = -1);\n",
    "classifier.fit(X_train, y);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I check that I've reached the 90% required accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the training with LG 0.9586263376283031\n"
     ]
    }
   ],
   "source": [
    "scoreLG = classifier.score(X_train, y)\n",
    "print ('Accuracy of the training with LG', scoreLG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy is above 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remark:  \n",
    "I splited the training data in two subgroups which I again call training and test. I use this approach to see the quality of the modelling testing on the subset not seing by the classifier during training. This is not crucial that is why I've comment this out. Accuracy on the randomly chosen testing data was about 83%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########\n",
    "# # I split the training data in two subgroups which I again call training and test. \n",
    "# # I use this test to see the quality of the modeling. \n",
    "# ########\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# sentences = training['text'].values\n",
    "# y = training['labelmax'].values\n",
    "\n",
    "# sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.1, random_state=1000)\n",
    "\n",
    "# vectorizer = CountVectorizer();\n",
    "# vectorizer.fit(sentences_train);\n",
    "# X_train = vectorizer.transform(sentences_train);\n",
    "# X_test  = vectorizer.transform(sentences_test);\n",
    "# X =  vectorizer.transform(sentences)\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# #logistic regression\n",
    "# classifier = LogisticRegression(multi_class = 'auto', n_jobs = -1);\n",
    "\n",
    "# # train withh the whole dataset\n",
    "# classifier.fit(X, y);\n",
    "# score_overLG = classifier.score(X, y)\n",
    "\n",
    "# # train with a subsample of the training data to test overfit\n",
    "# classifier.fit(X_train, y_train);\n",
    "# scoreLG = classifier.score(X_test, y_test)\n",
    "# print(\"Accuracy during training\", score_overLG)\n",
    "# print(\"Accuracy on a sub-sample of training\", scoreLG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "I now use the model learnt during training to make the predictions with the unlabelled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "labels = pd.DataFrame(classifier.predict(X_test), columns = ['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then define the Result dataet and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>company</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pros - super freundliche Kollegen - Weiterbild...</td>\n",
       "      <td>123makler</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pros - Fast pace - Lots of opportunities to gr...</td>\n",
       "      <td>Aaptiv</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pros Great leadership--team has the right focu...</td>\n",
       "      <td>Aaptiv</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pros The atmosphere and people create an amazi...</td>\n",
       "      <td>Aaptiv</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pros I really can't say enough positive things...</td>\n",
       "      <td>Aaptiv</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    company         labels\n",
       "0  Pros - super freundliche Kollegen - Weiterbild...  123makler           null\n",
       "1  Pros - Fast pace - Lots of opportunities to gr...     Aaptiv  collaboration\n",
       "2  Pros Great leadership--team has the right focu...     Aaptiv  collaboration\n",
       "3  Pros The atmosphere and people create an amazi...     Aaptiv   adaptability\n",
       "4  Pros I really can't say enough positive things...     Aaptiv  collaboration"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = pd.concat([testing,labels],axis = 1)\n",
    "Results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export the data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results.to_csv('resultsPredictions.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can one improve the analysis\n",
    "The crucial parts for improving the analysis are:\n",
    "1. pre-processing of the data, i.e. future engineering\n",
    "2. the choice of the classifier\n",
    "\n",
    "#### 1. Pre-processing\n",
    "By looking at the data we see the we have at least two languages: German and English. This should be taken into account, as suggested. Besides the language differences, one could take into account, e.g.:\n",
    "    1. ngrams\n",
    "    2. TF-IDF to highlight more interesting words at review level\n",
    "    3. remove stop words\n",
    "\n",
    "#### 2. Classifier\n",
    "    1. One could use different algorithms to perform the task. Among the most popular we have Naïve Bayes, Bayesian mixture models, SVM, tree-based approaches (gradient boosting, random-forest). Having time, the best strategy would be, clearly, to use a subsample of the training data, fit all the models and select the one which has the best performance. For this final step, we could use an n-fold cross-validation for each method and test the difference between the accuracies.\n",
    "    2. For each algorithm, we could also make a grid-search optimisation of the parameters.\n",
    "    \n",
    "#### I should use this analysis for business purposes? A remark.\n",
    "In case I should use this analysis for business purposes, I would need to present the results, e.g., to a customer. I would probably suggest to have at least two main visualisations. One would aggregate the results at company level using a voting scheme: the dimension receiving the most number of votes would characterise the current company culture. The second, more interesting approach, would be to characterise the company using all six dimensions. To visualise the data we could use a radar-plot. This second approach would allow to have a visual feedback about the current cultural-state and would highlight the dimensions on which the company should work. As Bunch, we could then propose actions (workshops, seminars, ..) to support the company to improve specific dimensions and use the radar-plots pre- and post-action to quantify the impact of the action itself.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of reviews\n",
    "ResultsGrouped = Results.groupby([\"company\"]).count()\n",
    "ResultsGrouped\n",
    "\n",
    "# AOL has 1255 I get  then only this company\n",
    "ResultsAOL = Results[Results[\"company\"] == \"AOL\"]\n",
    "ResultsAOL = ResultsAOL[ResultsAOL[\"labels\"]!='null']\n",
    "#count the number of reviews per each dimension and normalize as percentages\n",
    "ResultsAOL_dimension = 100*ResultsAOL.groupby([\"labels\"]).count()/1255\n",
    "ResultsAOL_dimension\n",
    "\n",
    "#radar visualisation\n",
    "\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Categories = ResultsAOL[\"labels\"].unique() \n",
    "N = len(Categories)\n",
    "Values = ResultsAOL_dimension[\"text\"].tolist()\n",
    "Values.append(Values[0]) #add value for periodicity\n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "Angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "Angles += Angles[:1]\n",
    "np.shape((Values))\n",
    "\n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    " \n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(Angles[:-1], Categories, color='grey', size=8)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,40)\n",
    " \n",
    "# Plot data\n",
    "ax.plot(Angles, Values, linewidth=1, linestyle='solid')\n",
    " \n",
    "# Fill area\n",
    "ax.fill(Angles, Values, 'b', alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to go into production\n",
    "This clearly depends on the business case. Important factor for deciding are the local infrastructure where the classifier should be available, how the classifier need to be used, and the customer's needs and constraints including legal limitations.\n",
    "We could have two possible approaches:\n",
    "1. put everything into a container which will be deployed on the server of a customer, for instance.\n",
    "2. expose an end-point to which one can request a prediction and get results. For this, one could use Azure or AWS. The basic workflow would be:\n",
    "<img src=\"workflow.png\" style=\"width: 700px;\" align=”left”/>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
